<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-10-26-metrics_eval_component.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This <a href="https://amygdala.github.io/gcp_blog/ml/kfp/kubeflow/keras/tensorflow/hp_tuning/2020/10/19/keras_tuner.html">blog post</a> and accompanying <a href="https://github.com/amygdala/code-snippets/blob/master/ml/kubeflow-pipelines/keras_tuner/README.md">tutorial</a> walked through how to build a <a href="https://www.kubeflow.org/docs/pipelines/">Kubeflow Pipelines</a> (KFP) pipeline that uses the <a href="https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html">Keras Tuner</a> to build a hyperparameter-tuning workflow that uses distributed HP search.</p>
<p>That pipeline does HP tuning, then runs full training on the N best parameter sets identified from the HP search, then deploys the full models to <a href="https://www.tensorflow.org/tfx/guide/serving">TF-serving</a>.<br />
One thing that was missing from that pipeline was any check on the quality of the trained models prior to deployment to TF-Serving.</p>
<p>This example is a follow-on to that tutorial.  Here, we show how you can create a KFP "lightweight component", built from a python function, to do a simple threshold check on some of the model metrics in order to decide whether to deploy the model. (This is a pretty simple approach, that we're using for illustrative purposes; for production models you'd probably want to do more sophisticated analyses. The <a href="https://www.tensorflow.org/tfx/model_analysis/get_started">TFMA library</a> might be of interest).</p>
<p>We'll also show how to use the KFP SDK to define and run pipelines from a notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setup">Setup<a class="anchor-link" href="#Setup"> </a></h2><p>This notebook assumes that you've <strong>done the setup indicated in the <a href="https://github.com/amygdala/code-snippets/blob/master/ml/kubeflow-pipelines/keras_tuner/README.md">README</a></strong>, and have an AI Platform Pipelines (Hosted KFP) installation, with GPU node pools added to the cluster.</p>
<h3 id="Create-an-AI-Platform-Notebooks-instance">Create an AI Platform Notebooks instance<a class="anchor-link" href="#Create-an-AI-Platform-Notebooks-instance"> </a></h3><p>In addition, create an AI Platform Notebooks instance on which to run this notebook. See setup instructions <a href="https://cloud.google.com/ai-platform/notebooks/docs">here</a>. (You can run this notebook in other environments, e.g. locally, but that requires additional auth setup that we won't go into here).</p>
<p><strong>Once your notebook instance is set up, you should be able to use <a href="https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name=Create%20a%20new%20KFP%20component%20from%20a%20notebook&amp;download_url=https%3A%2F%2Fraw.githubusercontent.com%2Famygdala%2Fcode-snippets%2Fmaster%2Fml%2Fkubeflow-pipelines%2Fkeras_tuner%2Fnotebooks%2Fmetrics_eval_component.ipynb&amp;url=https%3A%2F%2Fgithub.com%2Famygdala%2Fcode-snippets%2Fblob%2Fmaster%2Fml%2Fkubeflow-pipelines%2Fkeras_tuner%2Fnotebooks%2Fmetrics_eval_component.ipynb">this link</a> to upload and run the notebook.</strong></p>
<h3 id="Install-the-KFP-SDK">Install the KFP SDK<a class="anchor-link" href="#Install-the-KFP-SDK"> </a></h3><p>Next, we'll install the KFP SDK, and then restart the kernel so it's available for import.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install --user -U kfp kfp-server-api
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Restart kernel after the installs</span>
<span class="kn">import</span> <span class="nn">IPython</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">Application</span><span class="o">.</span><span class="n">instance</span><span class="p">()</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">do_shutdown</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we'll do some imports:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">kfp</span>  <span class="c1"># the Pipelines SDK. </span>
<span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">compiler</span>
<span class="kn">import</span> <span class="nn">kfp.dsl</span> <span class="k">as</span> <span class="nn">dsl</span>
<span class="kn">import</span> <span class="nn">kfp.gcp</span> <span class="k">as</span> <span class="nn">gcp</span>
<span class="kn">import</span> <span class="nn">kfp.components</span> <span class="k">as</span> <span class="nn">comp</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-a-new-'lightweight-component'-based-on-a-python-function">Defining a new 'lightweight component' based on a python function<a class="anchor-link" href="#Defining-a-new-'lightweight-component'-based-on-a-python-function"> </a></h2><p>'Lightweight' KFP python components allow you to create a component from a python function definition, and do not require you to build a new container image for every code change. They're helpful for fast iteration in a notebook environment. You can read more <a href="https://github.com/kubeflow/pipelines/blob/master/samples/core/lightweight_component/lightweight_component.ipynb">here</a>.</p>
<p>In this section, we'll create a lightweight component that uses training metrics info to decide whether to deploy a model.
We'll pass a "threshold" dict as a component arg, and compare those thresholds to the metrics values, and use that info to decide whether or not to deploy.  Then we'll output a string indicating the decision.</p>
<p>(As mentioned above, for production models you'd probably want to do a more substantial analysis. The <a href="https://www.tensorflow.org/tfx/model_analysis/get_started">TFMA library</a> might be of interest. Stay tuned for a follow-on post that uses TFMA).</p>
<p>Then we'll define a pipeline that uses the new component. In the pipeline spec, we'll make the 'serve' step conditional on the "metrics" op output.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First, we'll define the component function, <code>eval_metrics</code>:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>

<span class="k">def</span> <span class="nf">eval_metrics</span><span class="p">(</span>
  <span class="n">metrics</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
  <span class="n">thresholds</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Outputs&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;deploy&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">)]):</span>

  <span class="kn">import</span> <span class="nn">json</span>
  <span class="kn">import</span> <span class="nn">logging</span>

  <span class="k">def</span> <span class="nf">regression_threshold_check</span><span class="p">(</span><span class="n">metrics_info</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">thresholds_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;k </span><span class="si">{}</span><span class="s1">, v </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;root_mean_squared_error&#39;</span><span class="p">,</span> <span class="s1">&#39;mae&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">metrics_info</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">v</span><span class="p">:</span>
          <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> &gt; </span><span class="si">{}</span><span class="s1">; returning False&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics_info</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">v</span><span class="p">))</span>
          <span class="k">return</span> <span class="p">(</span><span class="s1">&#39;False&#39;</span><span class="p">,</span> <span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="s1">&#39;deploy&#39;</span><span class="p">,</span> <span class="p">)</span>

  <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>

  <span class="n">thresholds_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">thresholds</span><span class="p">)</span>
  <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;thresholds dict: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">thresholds_dict</span><span class="p">))</span>
  <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;metrics: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span>
  <span class="n">metrics_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>

  <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;got metrics info: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">metrics_dict</span><span class="p">)</span>
  <span class="n">res</span> <span class="o">=</span> <span class="n">regression_threshold_check</span><span class="p">(</span><span class="n">metrics_dict</span><span class="p">)</span>
  <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;deploy decision: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To keep things simple, we're comparing only RMSE and MAE with given threshold values.  (This function is tailored for our Keras regression model). Lower is better, so if a threshold value is higher than the associated model metric, we won't deploy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we'll create a 'container op' from the <code>eval_metrics</code> function definition, via the <code>funct_to_container_op</code> method. As one of the method args, we specify the base container image that will run the function. 
Here, we're using one of the <a href="https://cloud.google.com/ai-platform/deep-learning-containers/docs/">Deep Learning Container images</a>.  (This container image includes more than is necessary for this simple function, but these DL images can be useful for many ML-related components).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">eval_metrics_op</span> <span class="o">=</span> <span class="n">comp</span><span class="o">.</span><span class="n">func_to_container_op</span><span class="p">(</span><span class="n">eval_metrics</span><span class="p">,</span> <span class="n">base_image</span><span class="o">=</span><span class="s1">&#39;gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Define-a-pipeline-that-uses-the-new-&quot;metrics&quot;-op">Define a pipeline that uses the new "metrics" op<a class="anchor-link" href="#Define-a-pipeline-that-uses-the-new-&quot;metrics&quot;-op"> </a></h2><p>Now, we can define a new pipeline that uses the new op and makes the model serving conditional on the results.</p>
<p>The new <code>eval_metrics_op</code> takes as an input one of the <code>train_op</code> outputs, which outputs a final metrics dict. (We "cheated" a bit, as the training component was already designed to output this info; in other cases you might end up defining a new version of such an op that outputs the new info you need).</p>
<p>Then, we'll wrap the serving op in a <em>conditional</em>; we won't set up a TF-serving service unless the <code>eval_metrics</code> op has certified that it is okay.</p>
<p>Note that this new version of the pipeline also has a new input parameterâ€” the <code>thresholds</code> dict.</p>
<p>To keep things simple, we'll first define a pipeline that skips the HP tuning part of the pipeline used <a href="https://github.com/amygdala/code-snippets/blob/master/ml/kubeflow-pipelines/keras_tuner/README.md">here</a>.  This will make it easier to test your new op with a pipeline that takes a shorter time to run.</p>
<p>Then in a following section we'll show how to augment the full HP tuning pipeline to include the new op.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll first instantiate the other pipeline ops from their <a href="https://www.kubeflow.org/docs/pipelines/sdk/component-development/">reusable components</a> definitions.  (And we've defined the <code>eval_metrics_op</code> above).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_op</span> <span class="o">=</span> <span class="n">comp</span><span class="o">.</span><span class="n">load_component_from_url</span><span class="p">(</span>
  <span class="s1">&#39;https://raw.githubusercontent.com/amygdala/code-snippets/master/ml/kubeflow-pipelines/keras_tuner/components/train_component.yaml&#39;</span>
  <span class="p">)</span>
<span class="n">serve_op</span> <span class="o">=</span> <span class="n">comp</span><span class="o">.</span><span class="n">load_component_from_url</span><span class="p">(</span>
  <span class="s1">&#39;https://raw.githubusercontent.com/amygdala/code-snippets/master/ml/kubeflow-pipelines/keras_tuner/components/serve_component.yaml&#39;</span>
  <span class="p">)</span>

<span class="n">tb_op</span> <span class="o">=</span> <span class="n">comp</span><span class="o">.</span><span class="n">load_component_from_url</span><span class="p">(</span>
  <span class="s1">&#39;https://raw.githubusercontent.com/kubeflow/pipelines/master/components/tensorflow/tensorboard/prepare_tensorboard/component.yaml&#39;</span> 
  <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we'll define the pipeline itself.  You might notice that this pipeline has a new parameter, <code>thresholds</code>.</p>
<p>This pipeline first sets up a TensorBoard visualization for monitoring the training run. Then it starts the training. Once training is finished, the new op checks whether the trained model's final metrics are above the given threshold(s). 
If so (using the KFP <code>dsl.Condition</code> construct), TF-serving is used to set up a prediction service on the Pipelines GKE cluster.</p>
<p>You can see that data is being passed between the pipeline ops. <a href="https://gist.github.com/amygdala/bfa0f599a4814b3261367f558a852bfe">Here's a tutorial</a> that goes into how that works in more detail.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;bikes_weather_metrics&#39;</span><span class="p">,</span>
  <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Model bike rental duration given weather&#39;</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">bikes_weather_metrics</span><span class="p">(</span> 
  <span class="n">train_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
  <span class="n">working_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;gs://YOUR/GCS/PATH&#39;</span><span class="p">,</span>  <span class="c1"># for the full training jobs</span>
  <span class="n">data_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;gs://aju-dev-demos-codelabs/bikes_weather/&#39;</span><span class="p">,</span>
  <span class="n">steps_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="p">,</span>  <span class="c1"># if -1, don&#39;t override normal calcs based on dataset size</span>
  <span class="n">hptune_params</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;[{&quot;num_hidden_layers&quot;: </span><span class="si">%s</span><span class="s1">, &quot;learning_rate&quot;: </span><span class="si">%s</span><span class="s1">, &quot;hidden_size&quot;: </span><span class="si">%s</span><span class="s1">}]&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
  <span class="n">thresholds</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;{&quot;root_mean_squared_error&quot;: 2000}&#39;</span>
  <span class="p">):</span>

  <span class="c1"># create TensorBoard viz for the parent directory of all training runs, so that we can</span>
  <span class="c1"># compare them.</span>
  <span class="n">tb_viz</span> <span class="o">=</span> <span class="n">tb_op</span><span class="p">(</span>
    <span class="n">log_dir_uri</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="n">dsl</span><span class="o">.</span><span class="n">RUN_ID_PLACEHOLDER</span><span class="p">)</span>
  <span class="p">)</span>

  <span class="n">train</span> <span class="o">=</span> <span class="n">train_op</span><span class="p">(</span>
    <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span>
    <span class="n">workdir</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tb_viz</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;log_dir_uri&#39;</span><span class="p">],</span> <span class="mi">0</span><span class="p">),</span>
    <span class="n">tb_dir</span><span class="o">=</span><span class="n">tb_viz</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;log_dir_uri&#39;</span><span class="p">],</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">train_epochs</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
    <span class="n">hp_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
    <span class="n">hptune_results</span><span class="o">=</span><span class="n">hptune_params</span>
    <span class="p">)</span>

  <span class="n">eval_metrics</span> <span class="o">=</span> <span class="n">eval_metrics_op</span><span class="p">(</span>
    <span class="n">thresholds</span><span class="o">=</span><span class="n">thresholds</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;metrics_output_path&#39;</span><span class="p">],</span>
    <span class="p">)</span>

  <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">Condition</span><span class="p">(</span><span class="n">eval_metrics</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;deploy&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;deploy&#39;</span><span class="p">):</span>  <span class="c1"># conditional serving</span>
    <span class="n">serve</span> <span class="o">=</span> <span class="n">serve_op</span><span class="p">(</span>
      <span class="n">model_path</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;train_output_path&#39;</span><span class="p">],</span>
      <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;bikesw&#39;</span><span class="p">,</span>
      <span class="n">namespace</span><span class="o">=</span><span class="s1">&#39;default&#39;</span>
      <span class="p">)</span>
  <span class="n">train</span><span class="o">.</span><span class="n">set_gpu_limit</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can run the pipeline from the notebook.  First create a client object to talk to your KFP installation. Using that client, create (or get) an <em>Experiment</em> (which lets you create semantic groupings of pipeline runs).</p>
<p>You'll need to set the correct host endpoint for your pipelines installation when you create the client.  Visit the <a href="https://console.cloud.google.com/ai-platform/pipelines/clusters">Pipelines panel in the Cloud Console</a> and click on the <strong>SETTINGS</strong> gear for the desired installation to get its endpoint.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># CHANGE THIS with the info for your KFP cluster installation</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">kfp</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;xxxxxxxx-dot-us-centralx.pipelines.googleusercontent.com&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">exp</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">create_experiment</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;bw_expers&#39;</span><span class="p">)</span>  <span class="c1"># this is a &#39;get or create&#39; call</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>(If the <code>create_experiment</code> call failed, double check your host endpoint value).</p>
<p>Now, we can compile and then run the pipeline.  We'll set some vars with pipeline params:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">WORKING_DIR</span> <span class="o">=</span> <span class="s1">&#39;gs://YOUR_GCS/PATH&#39;</span>
<span class="n">TRAIN_EPOCHS</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we'll compile and run the pipeline.</p>
<p>Note that this pipeline is configured to use a GPU node for the training step, so make sure that you have set up a GPU node pool for the cluster that your KFP installation is running on, as described in this <a href="https://github.com/amygdala/code-snippets/blob/master/ml/kubeflow-pipelines/keras_tuner/README.md">README</a>. Note also that GPU nodes are more expensive.<br />
If you want, you can comment out the <code>train.set_gpu_limit(2)</code> line in the pipeline definition above to run training on a CPU node.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">compiler</span><span class="o">.</span><span class="n">Compiler</span><span class="p">()</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">bikes_weather_metrics</span><span class="p">,</span> <span class="s1">&#39;bikes_weather_metrics.tar.gz&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">run</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">run_pipeline</span><span class="p">(</span><span class="n">exp</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;bw_metrics_test&#39;</span><span class="p">,</span> <span class="s1">&#39;bikes_weather_metrics.tar.gz&#39;</span><span class="p">,</span>
                          <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;working_dir&#39;</span><span class="p">:</span> <span class="n">WORKING_DIR</span><span class="p">,</span> <span class="s1">&#39;train_epochs&#39;</span><span class="p">:</span> <span class="n">TRAIN_EPOCHS</span>
                                 <span class="c1"># &#39;thresholds&#39;: THRESHOLDS</span>
                                 <span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once you've kicked off the run, click the generated link to see the pipeline run in the Kubeflow Pipelines dashboard of your pipelines installation. (See the last section of this notebook for more info on how to use your trained and deployed model for prediction).</p>
<p><strong>Note</strong>: It's also possible to start a pipeline run directly from the pipeline function definition, skipping the local compilation, like this:</p>
<div class="highlight"><pre><span></span><span class="n">kfp</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="n">kfp_endpoint</span><span class="p">)</span><span class="o">.</span><span class="n">create_run_from_pipeline_func</span><span class="p">(</span><span class="o">&lt;</span><span class="n">pipeline_function_name</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">arguments</span><span class="o">=</span><span class="p">{})</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Use-the-new-&quot;metrics&quot;-op-with-the-full-Keras-Tuner-pipeline">Use the new "metrics" op with the full Keras Tuner pipeline<a class="anchor-link" href="#Use-the-new-&quot;metrics&quot;-op-with-the-full-Keras-Tuner-pipeline"> </a></h2><p>To keep things simple, the pipeline above didn't do an HP tuning search.
Below is how the full pipeline from <a href="https://github.com/amygdala/code-snippets/blob/master/ml/kubeflow-pipelines/keras_tuner/README.md">this tutorial</a> would be redefined to use this new op.</p>
<p>This definition assumes that you've run the cells above that instantiated the ops from their component specs. This new definition includes an additional <code>hptune</code> op (defined "inline" using <code>dsl.ContainerOp()</code>) that deploys the distributed HP tuning job and then waits for the results.</p>
<blockquote><p><strong>Important note</strong>:this example may take a long time to run, and <strong>incur significant charges</strong> in its use of GPUs, depending upon how its parameters are configured.</p>
</blockquote>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;bikes_weather_keras_tuner&#39;</span><span class="p">,</span>
  <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Model bike rental duration given weather, use Keras Tuner&#39;</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">bikes_weather_hptune</span><span class="p">(</span>
  <span class="n">tune_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
  <span class="n">train_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
  <span class="n">num_tuners</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
  <span class="n">bucket_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;YOUR_BUCKET_NAME&#39;</span><span class="p">,</span>  <span class="c1"># used for the HP dirs; don&#39;t include the &#39;gs://&#39;</span>
  <span class="n">tuner_dir_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;hptest&#39;</span><span class="p">,</span>
  <span class="n">tuner_proj</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;p1&#39;</span><span class="p">,</span>
  <span class="n">max_trials</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
  <span class="n">working_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;gs://YOUR/GCS/PATH&#39;</span><span class="p">,</span>  <span class="c1"># for the full training jobs</span>
  <span class="n">data_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;gs://aju-dev-demos-codelabs/bikes_weather/&#39;</span><span class="p">,</span>
  <span class="n">steps_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="p">,</span>  <span class="c1"># if -1, don&#39;t override normal calcs based on dataset size</span>
  <span class="n">num_best_hps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># the N best parameter sets for full training</span>
  <span class="c1"># the indices to the best param sets; necessary in addition to the above param because of</span>
  <span class="c1"># how KFP loops work currently.  Must be consistent with the above param.</span>
  <span class="n">num_best_hps_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
  <span class="n">thresholds</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;{&quot;root_mean_squared_error&quot;: 2000}&#39;</span>
  <span class="p">):</span>

  <span class="n">hptune</span> <span class="o">=</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerOp</span><span class="p">(</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ktune&#39;</span><span class="p">,</span>
      <span class="n">image</span><span class="o">=</span><span class="s1">&#39;gcr.io/google-samples/ml-pipeline-bikes-dep:b97ee76&#39;</span><span class="p">,</span>
      <span class="n">arguments</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--epochs&#39;</span><span class="p">,</span> <span class="n">tune_epochs</span><span class="p">,</span> <span class="s1">&#39;--num-tuners&#39;</span><span class="p">,</span> <span class="n">num_tuners</span><span class="p">,</span>
          <span class="s1">&#39;--tuner-dir&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tuner_dir_prefix</span><span class="p">,</span> <span class="n">dsl</span><span class="o">.</span><span class="n">RUN_ID_PLACEHOLDER</span><span class="p">),</span>
          <span class="s1">&#39;--tuner-proj&#39;</span><span class="p">,</span> <span class="n">tuner_proj</span><span class="p">,</span> <span class="s1">&#39;--bucket-name&#39;</span><span class="p">,</span> <span class="n">bucket_name</span><span class="p">,</span> <span class="s1">&#39;--max-trials&#39;</span><span class="p">,</span> <span class="n">max_trials</span><span class="p">,</span>
          <span class="s1">&#39;--namespace&#39;</span><span class="p">,</span> <span class="s1">&#39;default&#39;</span><span class="p">,</span> <span class="s1">&#39;--num-best-hps&#39;</span><span class="p">,</span> <span class="n">num_best_hps</span><span class="p">,</span> <span class="s1">&#39;--executions-per-trial&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
          <span class="s1">&#39;--deploy&#39;</span>
          <span class="p">],</span>
      <span class="n">file_outputs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;hps&#39;</span><span class="p">:</span> <span class="s1">&#39;/tmp/hps.json&#39;</span><span class="p">},</span>
      <span class="p">)</span>

  <span class="c1"># create TensorBoard viz for the parent directory of all training runs, so that we can</span>
  <span class="c1"># compare them.</span>
  <span class="n">tb_viz</span> <span class="o">=</span> <span class="n">tb_op</span><span class="p">(</span>
    <span class="n">log_dir_uri</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="n">dsl</span><span class="o">.</span><span class="n">RUN_ID_PLACEHOLDER</span><span class="p">)</span>
  <span class="p">)</span>

  <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ParallelFor</span><span class="p">(</span><span class="n">num_best_hps_list</span><span class="p">)</span> <span class="k">as</span> <span class="n">idx</span><span class="p">:</span>  <span class="c1"># start the full training runs in parallel</span>

    <span class="n">train</span> <span class="o">=</span> <span class="n">train_op</span><span class="p">(</span>
      <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span>
      <span class="n">workdir</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tb_viz</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;log_dir_uri&#39;</span><span class="p">],</span> <span class="n">idx</span><span class="p">),</span>
      <span class="n">tb_dir</span><span class="o">=</span><span class="n">tb_viz</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;log_dir_uri&#39;</span><span class="p">],</span>
      <span class="n">epochs</span><span class="o">=</span><span class="n">train_epochs</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
      <span class="n">hp_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">,</span> <span class="n">hptune_results</span><span class="o">=</span><span class="n">hptune</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;hps&#39;</span><span class="p">]</span>
      <span class="p">)</span>

    <span class="n">eval_metrics</span> <span class="o">=</span> <span class="n">eval_metrics_op</span><span class="p">(</span>
      <span class="n">thresholds</span><span class="o">=</span><span class="n">thresholds</span><span class="p">,</span>
      <span class="n">metrics</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;metrics_output_path&#39;</span><span class="p">],</span>
      <span class="p">)</span>

    <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">Condition</span><span class="p">(</span><span class="n">eval_metrics</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;deploy&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;deploy&#39;</span><span class="p">):</span>  <span class="c1"># conditional serving</span>
      <span class="n">serve</span> <span class="o">=</span> <span class="n">serve_op</span><span class="p">(</span>
        <span class="n">model_path</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;train_output_path&#39;</span><span class="p">],</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;bikesw&#39;</span><span class="p">,</span>
        <span class="n">namespace</span><span class="o">=</span><span class="s1">&#39;default&#39;</span>
        <span class="p">)</span>

    <span class="n">train</span><span class="o">.</span><span class="n">set_gpu_limit</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you want, you can compile and run this pipeline the same way as was done in the previous section. You can also find this pipeline in the example repo <a href="https://github.com/amygdala/code-snippets/blob/master/ml/kubeflow-pipelines/keras_tuner/example_pipelines/bw_ktune_metrics.py">here</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="More-detail-on-the-code,-and-requesting-predictions-from-your-model">More detail on the code, and requesting predictions from your model<a class="anchor-link" href="#More-detail-on-the-code,-and-requesting-predictions-from-your-model"> </a></h2><p>This notebook didn't focus on the details of the pipeline component (step) implementations.  The training component uses a Keras model (TF 2.3). The serving component uses <a href="https://www.tensorflow.org/tfx/guide/serving">TF-serving</a>: once the serving service is up and running, you can send prediction requests to your trained model.</p>
<p>You can find more detail on these components, and an example of sending a prediction request, <a href="https://github.com/amygdala/code-snippets/tree/master/ml/kubeflow-pipelines/keras_tuner">here</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Copyright 2020, Google, LLC. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at</p>
<p><a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></p>
<p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>

</div>
</div>
</div>
</div>

